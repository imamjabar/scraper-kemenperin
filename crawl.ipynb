{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def scrape_page(url):\n",
    "    # Add delay between requests\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Configure headers\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    # Make request with retries\n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed after {max_retries} attempts: {e}\")\n",
    "                return None, None\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying...\")\n",
    "            time.sleep(3)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract data from table\n",
    "    data = []\n",
    "    table_rows = soup.select(\"#newspaper-a tbody tr\")\n",
    "    \n",
    "    if not table_rows:\n",
    "        print(f\"No data found on page: {url}\")\n",
    "        return [], soup\n",
    "    \n",
    "    for row in table_rows:\n",
    "        try:\n",
    "            # Handle potential None values with safe access\n",
    "            nomor_cell = row.select_one(\"td:nth-child(1)\")\n",
    "            if not nomor_cell:\n",
    "                continue\n",
    "            # Remove dot from nomor\n",
    "            nomor = nomor_cell.text.strip().replace('.', '')\n",
    "            \n",
    "            perusahaan_cell = row.select_one(\"td:nth-child(2) b\")\n",
    "            if not perusahaan_cell:\n",
    "                continue\n",
    "            perusahaan = perusahaan_cell.text.strip()\n",
    "            \n",
    "            alamat_cell = row.select_one(\"td:nth-child(2)\")\n",
    "            if not alamat_cell:\n",
    "                continue\n",
    "                \n",
    "            kbli_cell = row.select_one(\"td:nth-child(3)\")\n",
    "            kbli = kbli_cell.text.strip() if kbli_cell else \"\"\n",
    "\n",
    "            # Get address parts by <br> tags\n",
    "            address_parts = [part.strip() for part in alamat_cell.get_text(separator='|').split('|') if part.strip()]\n",
    "            \n",
    "            # Remove company name from address parts\n",
    "            address_parts = [p for p in address_parts if p != perusahaan]\n",
    "            \n",
    "            # Last part usually contains phone number\n",
    "            telepon = \"\"\n",
    "            alamat_full = \"\"\n",
    "            if len(address_parts) > 0:\n",
    "                for part in address_parts:\n",
    "                    if \"Telp\" in part:\n",
    "                        telepon = part\n",
    "                    else:\n",
    "                        if alamat_full:\n",
    "                            alamat_full += \" \"\n",
    "                        alamat_full += part\n",
    "\n",
    "            # Split address into components by comma\n",
    "            addr_components = [x.strip() for x in alamat_full.split(',')]\n",
    "            \n",
    "            # Initialize address components\n",
    "            alamat = \"\"\n",
    "            kelurahan = \"\"\n",
    "            kecamatan = \"\"\n",
    "            kota = \"\"\n",
    "            provinsi = \"\"\n",
    "            \n",
    "            # Assign components based on position from end\n",
    "            if len(addr_components) >= 5:\n",
    "                provinsi = addr_components[-1]\n",
    "                kota = addr_components[-2]\n",
    "                kecamatan = addr_components[-3]\n",
    "                kelurahan = addr_components[-4]\n",
    "                alamat = ', '.join(addr_components[:-4])\n",
    "            elif len(addr_components) == 4:\n",
    "                provinsi = addr_components[-1]\n",
    "                kota = addr_components[-2]\n",
    "                kecamatan = addr_components[-3]\n",
    "                alamat = addr_components[-4]\n",
    "            elif len(addr_components) == 3:\n",
    "                provinsi = addr_components[-1]\n",
    "                kota = addr_components[-2]\n",
    "                alamat = addr_components[-3]\n",
    "            elif len(addr_components) == 2:\n",
    "                provinsi = addr_components[-1]\n",
    "                alamat = addr_components[-2]\n",
    "            elif len(addr_components) == 1:\n",
    "                alamat = addr_components[0]\n",
    "\n",
    "            data.append({\n",
    "                \"No\": nomor,\n",
    "                \"Perusahaan\": perusahaan,\n",
    "                \"Alamat\": alamat,\n",
    "                \"Kelurahan\": kelurahan,\n",
    "                \"Kecamatan\": kecamatan,\n",
    "                \"Kota\": kota,\n",
    "                \"Provinsi\": provinsi,\n",
    "                \"Telepon\": telepon,\n",
    "                \"KBLI\": kbli\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return data, soup\n",
    "\n",
    "def save_progress(current_province_index, current_url, record_count):\n",
    "    progress = {\n",
    "        \"current_province_index\": current_province_index,\n",
    "        \"current_url\": current_url,\n",
    "        \"record_count\": record_count,\n",
    "        \"last_updated\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    # Save progress to file\n",
    "    with open(\"output/scraping_progress.json\", \"w\") as f:\n",
    "        json.dump(progress, f, indent=2)\n",
    "    \n",
    "    # Get province name for logging\n",
    "    provinces = get_provinces()\n",
    "    province_name = provinces[current_province_index][\"name\"] if current_province_index < len(provinces) else \"Completed\"\n",
    "    print(f\"Progress saved. Current province: {province_name}, Records: {record_count}\")\n",
    "\n",
    "def load_progress():\n",
    "    if os.path.exists(\"output/scraping_progress.json\"):\n",
    "        try:\n",
    "            with open(\"output/scraping_progress.json\", \"r\") as f:\n",
    "                progress = json.load(f)\n",
    "            \n",
    "            print(f\"Resuming from previous session: {progress['last_updated']}\")\n",
    "            return progress\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading progress file: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_provinces():\n",
    "    # Define provinces to scrape - centralized in one place\n",
    "    return [\n",
    "        {\"name\": \"Bali\", \"code\": \"0bCtGgIPKU5sHVP-I3RJR_zaGkICRuxrBuLF8pn6okw,\"},\n",
    "        {\"name\": \"Banten\", \"code\": \"szh3Nx9NmSTOTpqeCuh7rOYNcZov8Oricx3WNJaMJkg,\"},\n",
    "        {\"name\": \"Bengkulu\", \"code\": \"7PXdLsCfLTabVYR-HdFCQ1lgobeRW7wKz4lderTiLAA,\"},\n",
    "        {\"name\": \"DI Yogyakarta\", \"code\": \"YaPZnRqzpP2obO5M2vJBT-05qeMzPo7KQSLLhi4zW28,\"},\n",
    "        {\"name\": \"DKI Jakarta\", \"code\": \"JWlMr9dBZoh4NcRGhLV2lw1ZzJLjyJbE3zQxksmdgRg,\"},\n",
    "        {\"name\": \"Gorontalo\", \"code\": \"lj03S7Gb2eruSZuL8ba_7yLcdYZJ-4LWKyIXOfQRw_Y,\"},\n",
    "        {\"name\": \"Jambi\", \"code\": \"sY3Wej_tKISCKJBFQVPbgxGBtclmA1CBsP2XzHLIQnE,\"},\n",
    "        {\"name\": \"Jawa Barat\", \"code\": \"g-g92cJf63GcZzFru_hX80HG3NA95zwE5tWTVGAI5xY,\"},\n",
    "        {\"name\": \"Jawa Tengah\", \"code\": \"JQYaw_F3IWxjLT5vFsXUh6CwfCBsw3zUdgJGGaNtqc0,\"},\n",
    "        {\"name\": \"Jawa Timur\", \"code\": \"HJCA4sCEb2EHadmM-d2MTdZLHIqCSlODwIEaR0IZuz0,\"},\n",
    "        {\"name\": \"Kalimantan Barat\", \"code\": \"IxrCrXAp3g1zI59mewRpTAmQPCTS890Aict2e5UMFTc,\"},\n",
    "        {\"name\": \"Kalimantan Selatan\", \"code\": \"lNWKArPtvRuMF1NSp4iFoz2d5bnuzIiwQ2vkyHhak_0,\"},\n",
    "        {\"name\": \"Kalimantan Tengah\", \"code\": \"IBaS1sFWk7P4GBK8cUj0wJQECSfN05EH7hE3fSYvcsI,\"},\n",
    "        {\"name\": \"Kalimantan Timur\", \"code\": \"mtGQZOTaw8Pwbfknh9NnVNXHPjm3AYU24il3lqoHsKY,\"},\n",
    "        {\"name\": \"Kalimantan Utara\", \"code\": \"9l2EyMtxPzG7DrI1BYbqzO2dsYxmSrsR-F5mUuznkUI,\"},\n",
    "        {\"name\": \"Kepulauan Bangka Belitung\", \"code\": \"qPoGfR2CPXOIzHC-qtcv3dZPViN_U5d_HfvBDijVZDU,\"},\n",
    "        {\"name\": \"Kepulauan Riau\", \"code\": \"d_6LRe0K-myaHNofmityPTFUXnCdgWUDYPbIwv41Lpo,\"},\n",
    "        {\"name\": \"Lampung\", \"code\": \"EtDhV24I_AgUTjwdPnaAJCuEdnS41hZIYUPlkeLCd04,\"},\n",
    "        {\"name\": \"Luar Negeri\", \"code\": \"QAjmoLvOjrGxggCMLV73K4-Z1v3XRBEIOjJ5r4KRRII,\"},\n",
    "        {\"name\": \"Maluku\", \"code\": \"zNm24FybEw4j4JVWEbA14S2YgBKEkGiHknYNpZNps88,\"},\n",
    "        {\"name\": \"Maluku Utara\", \"code\": \"rY-Vee9aPuuq68KevO_FPXkNFm_LAavy4LvMDC86yf0,\"},\n",
    "        {\"name\": \"Nangroe Aceh Darussalam\", \"code\": \"qH6KCKkWFhD8UGv2rwsLvzOk-778LwSl9O2-qCSP-x8,\"},\n",
    "        {\"name\": \"Nusa Tenggara Barat\", \"code\": \"DRelepyjdDkPntAag94avf-ou4ALhHIRkWctL4k3cxk,\"},\n",
    "        {\"name\": \"Nusa Tenggara Timur\", \"code\": \"mC-0BzjjZqLYu-Kkc9Rg4j15GLTQBzgR3uIgp3mgKSg,\"},\n",
    "        {\"name\": \"Papua\", \"code\": \"RdPXmu5cadJ7SQLmAalkvlc1qJA4XYziZUJL6kLsePs,\"},\n",
    "        {\"name\": \"Papua Barat\", \"code\": \"of0LzbEMgs5YXxmpnXy5hL9vkPwtQy-j8nlEBIjZMy4,\"},\n",
    "        {\"name\": \"Papua Barat Daya\", \"code\": \"jNG3dvTuNYIoPv1m8HWs-vghiRVIYvMkKg18O9kKAyo,\"},\n",
    "        {\"name\": \"Papua Pegunungan\", \"code\": \"9BGr8lSPa1IfmvK8n-rRQjN7e3QdCzLKpvCQetCwT2Q,\"},\n",
    "        {\"name\": \"Papua Selatan\", \"code\": \"ub8mQqHT259JPsWjDrZxfJNswELNe2ODk4No391hiKM,\"},\n",
    "        {\"name\": \"Papua Tengah\", \"code\": \"4kld4CXPtKFdCyuTe_2kU8EIn5s-TipyTDFQ8RGHcHo,\"},\n",
    "        {\"name\": \"Riau\", \"code\": \"h5kdoWTdkKA6SJRYKVGHBzC_kzW74s0P5uSTAZ3Qeqs,\"},\n",
    "        {\"name\": \"Sulawesi Barat\", \"code\": \"uyqjnkrb04MuauY79cEh_jydyZPiKrNgd__nBrN89W0,\"},\n",
    "        {\"name\": \"Sulawesi Selatan\", \"code\": \"NgxlXm4O9RisBSPbBxFCkU3EICDeSjBUOKkjQSYLo2c,\"},\n",
    "        {\"name\": \"Sulawesi Tengah\", \"code\": \"75xafGvwr11mzUWpufY1t8OR4CJHbvT1cfvt7N7sO10,\"},\n",
    "        {\"name\": \"Sulawesi Tenggara\", \"code\": \"AJ1mml5HqF88qgIV7PYpX4zyWJ7G0jCWodfIKonUyPM,\"},\n",
    "        {\"name\": \"Sulawesi Utara\", \"code\": \"wALq168Ez0AZMs5Nc3aoSM5Zr-E0jM0Z_hYKkl-i2Zo,\"},\n",
    "        {\"name\": \"Sumatera Barat\", \"code\": \"dH1L8Mh_lQt9ynweGqgAQt06SfXnOsW51ueJX7uv5Kg,\"},\n",
    "        {\"name\": \"Sumatera Selatan\", \"code\": \"LT6Nl1-93HfnTOoo8L8ysPSKCRwmEnlqszx6HfH2tdk,\"},\n",
    "        {\"name\": \"Sumatera Utara\", \"code\": \"ehCDQCBFt5DYprYqIgwr1h-bqWX8nCstPP1LL3NuLXY,\"}\n",
    "    ]\n",
    "\n",
    "def is_scraping_completed(progress):\n",
    "    \"\"\"Check if scraping is already completed based on progress file\"\"\"\n",
    "    if not progress:\n",
    "        return False\n",
    "    \n",
    "    provinces = get_provinces()\n",
    "    \n",
    "    # If current_province_index is beyond the last province index, scraping is complete\n",
    "    if progress.get(\"current_province_index\", 0) >= len(provinces):\n",
    "        return True\n",
    "    \n",
    "    # If current_url is None and we're at the last province, it might be complete\n",
    "    if progress.get(\"current_url\") is None and progress.get(\"current_province_index\", 0) == len(provinces) - 1:\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://kemenperin.go.id/direktori-perusahaan\"\n",
    "    output_file = \"output/kemenperin.csv\"\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    \n",
    "    # Check if file exists to determine if we need to write headers\n",
    "    file_exists = os.path.exists(output_file)\n",
    "    record_count = 0\n",
    "    \n",
    "    # Count existing records if file exists\n",
    "    if file_exists:\n",
    "        try:\n",
    "            with open(output_file, 'r', encoding='utf-8') as f:\n",
    "                record_count = sum(1 for _ in f) - 1  # Subtract 1 for header\n",
    "            print(f\"Found existing file with {record_count} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error counting existing records: {e}\")\n",
    "            record_count = 0\n",
    "    \n",
    "    # Get provinces list\n",
    "    provinces = get_provinces()\n",
    "    \n",
    "    # Check for saved progress\n",
    "    progress = load_progress()\n",
    "    \n",
    "    # Check if scraping is already completed\n",
    "    if is_scraping_completed(progress):\n",
    "        print(\"Scraping was already completed in the previous run.\")\n",
    "        print(f\"Last update: {progress.get('last_updated')}\")\n",
    "        print(f\"Total records: {progress.get('record_count', record_count)}\")\n",
    "        return\n",
    "    \n",
    "    current_province_index = 0\n",
    "    current_url = None\n",
    "    \n",
    "    if progress:\n",
    "        current_province_index = progress.get(\"current_province_index\", 0)\n",
    "        current_url = progress.get(\"current_url\")\n",
    "        record_count = progress.get(\"record_count\", record_count)\n",
    "        \n",
    "        # Check if current_province_index is valid\n",
    "        if current_province_index < len(provinces):\n",
    "            print(f\"Resuming with province: {provinces[current_province_index]['name']}\")\n",
    "            if current_url:\n",
    "                print(f\"Starting URL: {current_url}\")\n",
    "            else:\n",
    "                current_url = f\"{base_url}?what=&prov={provinces[current_province_index]['code']}\"\n",
    "                print(f\"No URL saved, starting with: {current_url}\")\n",
    "        else:\n",
    "            # Index out of range, reset to start with the first province\n",
    "            print(\"Saved province index is out of range. Starting from the beginning.\")\n",
    "            current_province_index = 0\n",
    "            current_url = f\"{base_url}?what=&prov={provinces[0]['code']}\"\n",
    "    else:\n",
    "        # No progress file, start with first province\n",
    "        current_url = f\"{base_url}?what=&prov={provinces[0]['code']}\"\n",
    "    \n",
    "    # Define headers for CSV\n",
    "    headers = [\"No\", \"Perusahaan\", \"Alamat\", \"Kelurahan\", \"Kecamatan\", \"Kota\", \"Provinsi\", \"Telepon\", \"KBLI\"]\n",
    "    \n",
    "    # Write headers if file doesn't exist\n",
    "    if not file_exists:\n",
    "        with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(headers)\n",
    "    \n",
    "    try:\n",
    "        # Process each province starting from the saved position\n",
    "        for i in range(current_province_index, len(provinces)):\n",
    "            province = provinces[i]\n",
    "            print(f\"\\nProcessing province: {province['name']}\")\n",
    "            \n",
    "            # Set the starting URL\n",
    "            if i == current_province_index and current_url:\n",
    "                url = current_url\n",
    "            else:\n",
    "                url = f\"{base_url}?what=&prov={province['code']}\"\n",
    "            \n",
    "            while url:\n",
    "                print(f\"Scraping: {url}\")\n",
    "                page_data, soup = scrape_page(url)\n",
    "                \n",
    "                # Check if soup is None (request failed)\n",
    "                if soup is None:\n",
    "                    print(f\"Failed to get data for {url}, skipping to next province\")\n",
    "                    break\n",
    "                \n",
    "                if page_data:\n",
    "                    # Append data to CSV file directly\n",
    "                    with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        for item in page_data:\n",
    "                            writer.writerow([\n",
    "                                item[\"No\"],\n",
    "                                item[\"Perusahaan\"],\n",
    "                                item[\"Alamat\"],\n",
    "                                item[\"Kelurahan\"],\n",
    "                                item[\"Kecamatan\"],\n",
    "                                item[\"Kota\"],\n",
    "                                item[\"Provinsi\"],\n",
    "                                item[\"Telepon\"],\n",
    "                                item[\"KBLI\"]\n",
    "                            ])\n",
    "                    \n",
    "                    record_count += len(page_data)\n",
    "                    print(f\"Scraped {len(page_data)} records. Total records: {record_count}\")\n",
    "                    \n",
    "                    # Get next page URL\n",
    "                    try:\n",
    "                        active_item = soup.select_one('.pagination li.active')\n",
    "                        \n",
    "                        if active_item and active_item.find_next_sibling('li'):\n",
    "                            next_item = active_item.find_next_sibling('li')\n",
    "                            next_link = next_item.find('a')\n",
    "                            if next_link and next_link.get('href'):\n",
    "                                next_href = next_link['href']\n",
    "                                next_href = next_href.replace('direktori-perusahaan', '', 1)\n",
    "                                url = base_url + next_href\n",
    "                            else:\n",
    "                                url = None\n",
    "                        else:\n",
    "                            url = None\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error finding next page: {e}\")\n",
    "                        url = None\n",
    "                else:\n",
    "                    print(\"No data found on page, moving to next province\")\n",
    "                    url = None\n",
    "                \n",
    "                # Save progress after each page\n",
    "                save_progress(i, url, record_count)\n",
    "                \n",
    "                # Add delay between pages\n",
    "                if url:\n",
    "                    print(f\"Next URL: {url}\")\n",
    "                    time.sleep(2)\n",
    "            \n",
    "            # Update progress when moving to next province\n",
    "            current_province_index = i + 1\n",
    "            if current_province_index < len(provinces):\n",
    "                current_url = f\"{base_url}?what=&prov={provinces[current_province_index]['code']}\"\n",
    "                save_progress(current_province_index, current_url, record_count)\n",
    "            \n",
    "            # Add delay between provinces\n",
    "            time.sleep(5)\n",
    "        \n",
    "        print(\"Scraping completed successfully!\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nScraping interrupted by user.\")\n",
    "        save_progress(current_province_index, url, record_count)\n",
    "        print(\"Progress saved. You can resume later.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError occurred: {e}\")\n",
    "        save_progress(current_province_index, url, record_count)\n",
    "        print(\"Progress saved despite error.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
